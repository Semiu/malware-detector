{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CombiningCategoricalCols.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRCDpUsz5bEb"
      },
      "source": [
        "Categorical columns are combined to create a degree of two as a feature engineering process intended to improve the performance of the basic model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZBzzNEemunl"
      },
      "source": [
        "#Import the libraries\r\n",
        "import itertools\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "from tqdm import tqdm\r\n",
        "from sklearn import ensemble\r\n",
        "from sklearn import linear_model, metrics, preprocessing\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "import xgboost as xgb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBmxP6Lv7frI"
      },
      "source": [
        "#Load the data - The datsset used for the modeling, the fractional data, is loaded directly\r\n",
        "modeling_dataset = pd.read_csv('/content/drive/MyDrive/prediction/frac_cleaned_fod_data.csv', low_memory = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilhI_ElC7jiG"
      },
      "source": [
        "#All columns except 'HasDetections', 'kfold', and 'MachineIdentifier' as training features\r\n",
        "train_features = [tf for tf in modeling_dataset.columns if tf not in ('HasDetections', 'kfold', 'MachineIdentifier')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B853IeAx7mpH"
      },
      "source": [
        "#Define the categorical features of the data\r\n",
        "categorical_features = ['ProductName',\r\n",
        "                        'EngineVersion',\r\n",
        "                        'AppVersion',\r\n",
        "                        'AvSigVersion',\r\n",
        "                        'Platform',\r\n",
        "                        'Processor',\r\n",
        "                        'OsVer',\r\n",
        "                        'OsPlatformSubRelease',\r\n",
        "                        'OsBuildLab',\r\n",
        "                        'SkuEdition',\r\n",
        "                        'Census_MDC2FormFactor',\r\n",
        "                        'Census_DeviceFamily',\r\n",
        "                        'Census_PrimaryDiskTypeName',\r\n",
        "                        'Census_ChassisTypeName',\r\n",
        "                        'Census_PowerPlatformRoleName',\r\n",
        "                        'Census_OSVersion',\r\n",
        "                        'Census_OSArchitecture',\r\n",
        "                        'Census_OSBranch',\r\n",
        "                        'Census_OSEdition',\r\n",
        "                        'Census_OSSkuName',\r\n",
        "                        'Census_OSInstallTypeName',\r\n",
        "                        'Census_OSWUAutoUpdateOptionsName',\r\n",
        "                        'Census_GenuineStateName',\r\n",
        "                        'Census_ActivationChannel',\r\n",
        "                        'Census_FlightRing']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-0TKEOk6OGU"
      },
      "source": [
        "#Feature engineering function\r\n",
        "def feature_engineering(df, cat_cols):\r\n",
        "  \"\"\"\r\n",
        "  This function is used for feature engineering\r\n",
        "  :param df: the pandas dataframe with train/test data\r\n",
        "  :param cat_cols: list of categorical columns\r\n",
        "  : return: dataframe with new features\r\n",
        "  \"\"\"\r\n",
        "  #For clarity, list(itertools.combinations([1,2,3], 2)) will return \r\n",
        "  #[(1,2),(1,3),(2,3)]\r\n",
        "\r\n",
        "  combi = list(itertools.combinations(cat_cols, 2))\r\n",
        "  for c1, c2 in combi:\r\n",
        "    df.loc[\r\n",
        "           :,\r\n",
        "           c1 + \"_\" + c2\r\n",
        "    ] = df[c1].astype(str) + \"_\" + df[c2].astype(str)\r\n",
        "  \r\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhZODzmi6ODr"
      },
      "source": [
        "#Function for XGBoost model\r\n",
        "def run_xgb(fold):\r\n",
        "  #Call the feature engineering function\r\n",
        "  engineered_modeling_dataset = feature_engineering(modeling_dataset, categorical_features)\r\n",
        "  #Label encode the categorical features\r\n",
        "  for col in train_features:\r\n",
        "    if col in categorical_features:\r\n",
        "      #Initialize Label encoder for each categorical column\r\n",
        "      lbl = preprocessing.LabelEncoder()\r\n",
        "\r\n",
        "      lbl.fit(engineered_modeling_dataset[col])\r\n",
        "      #Transform\r\n",
        "      engineered_modeling_dataset.loc[:,col] = lbl.transform(engineered_modeling_dataset[col])\r\n",
        "  #Get the training and validation data\r\n",
        "  engineered_modeling_dataset_train = engineered_modeling_dataset[engineered_modeling_dataset.kfold != fold].reset_index(drop=True)\r\n",
        "  engineered_modeling_dataset_valid = engineered_modeling_dataset[engineered_modeling_dataset.kfold == fold].reset_index(drop=True)\r\n",
        "\r\n",
        "  x_train = engineered_modeling_dataset_train[train_features].values\r\n",
        "  x_valid = engineered_modeling_dataset_valid[train_features].values\r\n",
        "\r\n",
        "  #Initialize XGboost model\r\n",
        "  xgb_model = xgb.XGBClassifier(n_jobs=-1)\r\n",
        "  #Fit the model on training data\r\n",
        "  xgb_model.fit(x_train, engineered_modeling_dataset_train.HasDetections.values)\r\n",
        "\r\n",
        "  #Predict on validation\r\n",
        "  valid_preds = xgb_model.predict_proba(x_valid)[:,1]\r\n",
        "\r\n",
        "  valid_preds_others = xgb_model.predict(x_valid)\r\n",
        "\r\n",
        "  #Get the ROC AUC score\r\n",
        "  auc = metrics.roc_auc_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds)\r\n",
        "\r\n",
        "  #Get the precision score\r\n",
        "  pre = metrics.precision_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds, average='binary')\r\n",
        "\r\n",
        "  #Get the Recall score\r\n",
        "  rc = metrics.recall_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds, average='binary')\r\n",
        "\r\n",
        "  return auc, pre, rc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGuMo62V6OBE"
      },
      "source": [
        "run_xgb(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0IVuu8I6N-K"
      },
      "source": [
        "#Function for Neural Network model\r\n",
        "def run_nn(fold):\r\n",
        "  #Call the feature engineering function\r\n",
        "  engineered_modeling_dataset = feature_engineering(modeling_dataset, categorical_features)\r\n",
        "\r\n",
        "  #Get the training and validation data\r\n",
        "  engineered_modeling_dataset_train = engineered_modeling_dataset[engineered_modeling_dataset.kfold != fold].reset_index(drop=True)\r\n",
        "  engineered_modeling_dataset_valid = engineered_modeling_dataset[engineered_modeling_dataset.kfold == fold].reset_index(drop=True)\r\n",
        "  #OneHotEncoder\r\n",
        "  ohe = preprocessing.OneHotEncoder()\r\n",
        "  full_data = pd.concat(\r\n",
        "    [engineered_modeling_dataset_train[train_features],engineered_modeling_dataset_valid[train_features]],\r\n",
        "    axis = 0\r\n",
        "    )\r\n",
        "  ohe.fit(full_data[train_features])\r\n",
        "\r\n",
        "  #Scale the data\r\n",
        "  X_train = ohe.transform(engineered_modeling_dataset_train[train_features])\r\n",
        "  X_valid = ohe.transform(engineered_modeling_dataset_valid[train_features])\r\n",
        "\r\n",
        "  #Initialize the Neural Network Model\r\n",
        "  nn_model = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\r\n",
        "\r\n",
        "  #Fit the model on training data\r\n",
        "  nn_model.fit(X_train, engineered_modeling_dataset_train.HasDetections.values)\r\n",
        "\r\n",
        "  #Predict on validation\r\n",
        "  valid_preds = nn_model.predict_proba(X_valid)[:,1]\r\n",
        "\r\n",
        "  valid_preds_others = nn_model.predict(X_valid)\r\n",
        "\r\n",
        "  #Get the ROC AUC score\r\n",
        "  auc = metrics.roc_auc_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds)\r\n",
        "\r\n",
        "  #Get the precision score\r\n",
        "  pre = metrics.precision_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds_others, average='binary')\r\n",
        "\r\n",
        "  #Get the Recall score\r\n",
        "  rc = metrics.recall_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds_others, average='binary')\r\n",
        "\r\n",
        "  return auc, pre, rc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB7hQtpPLl4a"
      },
      "source": [
        "run_nn(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHVQK4BD6N7U"
      },
      "source": [
        "#Function for Logistic Regression model\r\n",
        "def run_lr(fold):\r\n",
        "  #Call the feature engineering function\r\n",
        "  engineered_modeling_dataset = feature_engineering(modeling_dataset, categorical_features)\r\n",
        "\r\n",
        "  #Get the training and validation data\r\n",
        "  engineered_modeling_dataset_train = engineered_modeling_dataset[engineered_modeling_dataset.kfold != fold].reset_index(drop=True)\r\n",
        "  engineered_modeling_dataset_valid = engineered_modeling_dataset[engineered_modeling_dataset.kfold == fold].reset_index(drop=True)\r\n",
        "  #OneHotEncoder\r\n",
        "  ohe = preprocessing.OneHotEncoder()\r\n",
        "  full_data = pd.concat(\r\n",
        "    [engineered_modeling_dataset_train[train_features],engineered_modeling_dataset_valid[train_features]],\r\n",
        "    axis = 0\r\n",
        "    )\r\n",
        "  ohe.fit(full_data[train_features])\r\n",
        "\r\n",
        "  #Scale the data\r\n",
        "  X_train = ohe.transform(engineered_modeling_dataset_train[train_features])\r\n",
        "  X_valid = ohe.transform(engineered_modeling_dataset_valid[train_features])\r\n",
        "\r\n",
        "  #Initialize the Logistic Regression Model\r\n",
        "  lr_model = linear_model.LogisticRegression()\r\n",
        "  \r\n",
        "  #Fit the model on training data\r\n",
        "  lr_model.fit(X_train, engineered_modeling_dataset_train.HasDetections.values)\r\n",
        "\r\n",
        "\r\n",
        "  #Predict on validation\r\n",
        "  valid_preds = lr_model.predict_proba(X_valid)[:,1]\r\n",
        "\r\n",
        "  valid_preds_others = lr_model.predict(X_valid)\r\n",
        "\r\n",
        "  #Get the ROC AUC score\r\n",
        "  auc = metrics.roc_auc_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds)\r\n",
        "\r\n",
        "  #Get the precision score\r\n",
        "  pre = metrics.precision_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds_others, average='binary')\r\n",
        "\r\n",
        "  #Get the Recall score\r\n",
        "  rc = metrics.recall_score(engineered_modeling_dataset_valid.HasDetections.values, valid_preds_others, average='binary')\r\n",
        "\r\n",
        "  return auc, pre, rc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5hYoKxU6N4s"
      },
      "source": [
        "run_lr(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eATc0Uga6N19"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R60TqpYi6iai"
      },
      "source": [
        "Unfortunately, this created so many new columns that it crashes the session repeatedly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQL1kcW36tja"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}