{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelection4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4jdN--xcWmD"
      },
      "source": [
        "Training basic model with selected features based on Feature importance ranking. Models to be trained are Logistic Regression, Neural Network and XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lWXAkewbmKE"
      },
      "source": [
        "#Import the libraries \n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn import linear_model, metrics, preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9U7NQcDb8bF"
      },
      "source": [
        "#Load the data\n",
        "modeling_dataset = pd.read_csv('/content/drive/MyDrive/prediction/frac_cleaned_fod_data.csv', low_memory = False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcsin3xte4zF"
      },
      "source": [
        "#All columns - for tree\n",
        "train_features = [tf for tf in modeling_dataset.columns if tf not in ('HasDetections', 'kfold', 'MachineIdentifier')]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfeax2kPVmZr"
      },
      "source": [
        "#Training features\n",
        "\"\"\"\n",
        "train_features_after_selection = [tf for tf in modeling_dataset.columns if tf not in ('HasDetections', 'kfold', 'MachineIdentifier', 'Unnamed: 0', 'OsVer', 'UacLuaenable', 'Census_DeviceFamily', 'Census_OSArchitecture', \n",
        "                                                                                      'AutoSampleOptln', 'Census_OSBuildNumber', 'IsBeta', 'CensusIsFlightsDisabled', 'Census_IsPenCapable', 'ProductName', 'Census_IsPortableOperatingSystem', \n",
        "                                                                                      'CityIdentifier', 'HasTpm', 'OsPlatformSubRelease', 'Census_IsSecureBootEnabled', 'Census_OSBranch', 'Census_PrimaryDiskTypeName', 'Platform',\n",
        "                                                                                      'Census_GenuineStateName', 'SkuEdition')]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhKmf9rPCMO0"
      },
      "source": [
        "train_features_after_selection = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncwSxkWWbmNR"
      },
      "source": [
        "#Define the categorical features of the data\n",
        "categorical_features = ['ProductName',\n",
        "                        'EngineVersion',\n",
        "                        'AppVersion',\n",
        "                        'AvSigVersion',\n",
        "                        'Platform',\n",
        "                        'Processor',\n",
        "                        'OsVer',\n",
        "                        'OsPlatformSubRelease',\n",
        "                        'OsBuildLab',\n",
        "                        'SkuEdition',\n",
        "                        'Census_MDC2FormFactor',\n",
        "                        'Census_DeviceFamily',\n",
        "                        'Census_PrimaryDiskTypeName',\n",
        "                        'Census_ChassisTypeName',\n",
        "                        'Census_PowerPlatformRoleName',\n",
        "                        'Census_OSVersion',\n",
        "                        'Census_OSArchitecture',\n",
        "                        'Census_OSBranch',\n",
        "                        'Census_OSEdition',\n",
        "                        'Census_OSSkuName',\n",
        "                        'Census_OSInstallTypeName',\n",
        "                        'Census_OSWUAutoUpdateOptionsName',\n",
        "                        'Census_GenuineStateName',\n",
        "                        'Census_ActivationChannel',\n",
        "                        'Census_FlightRing']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DOpH9Yw_aY7"
      },
      "source": [
        "#Function for the Logistic Regression Classifier - OHE\n",
        "def run_lr_ohe(fold):\n",
        "  #Get training and validation data using folds\n",
        "  cleaned_fold_datasets_train = modeling_dataset[modeling_dataset.kfold != fold].reset_index(drop=True)\n",
        "  cleaned_fold_datasets_valid = modeling_dataset[modeling_dataset.kfold == fold].reset_index(drop=True)\n",
        "  \n",
        "  #Initialize OneHotEncoder from scikit-learn, and fit it on training and validation features\n",
        "  ohe = preprocessing.OneHotEncoder()\n",
        "  full_data = pd.concat(\n",
        "    [cleaned_fold_datasets_train[train_features_after_selection],cleaned_fold_datasets_valid[train_features_after_selection]],\n",
        "    axis = 0\n",
        "    )\n",
        "  ohe.fit(full_data[train_features_after_selection])\n",
        "  \n",
        "  #transform the training and validation data\n",
        "  x_train = ohe.transform(cleaned_fold_datasets_train[train_features_after_selection])\n",
        "  x_valid = ohe.transform(cleaned_fold_datasets_valid[train_features_after_selection])\n",
        "\n",
        "  #Initialize the Logistic Regression Model\n",
        "  lr_model = linear_model.LogisticRegression()\n",
        "\n",
        "  #Fit model on training data (ohe)\n",
        "  lr_model.fit(x_train, cleaned_fold_datasets_train.HasDetections.values)\n",
        "\n",
        "  #Predict on the validation data using the probability of 1s for the AUC\n",
        "  valid_preds = lr_model.predict_proba(x_valid)[:, 1]\n",
        "\n",
        "  valid_preds_pc = lr_model.predict(x_valid)\n",
        "\n",
        "\n",
        "  #Get the ROC AUC score\n",
        "  auc = metrics.roc_auc_score(cleaned_fold_datasets_valid.HasDetections.values, valid_preds)\n",
        "\n",
        "  #Get the precision score\n",
        "  pre = metrics.precision_score(cleaned_fold_datasets_valid.HasDetections.values, valid_preds_pc, average='binary')\n",
        "\n",
        "  #Get the Recall score\n",
        "  rc = metrics.recall_score(cleaned_fold_datasets_valid.HasDetections.values, valid_preds_pc, average='binary')\n",
        "\n",
        "  return auc, pre, rc"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fm1I5JvAln6",
        "outputId": "a270e0c9-8540-4625-db7e-882c0c8cee4f"
      },
      "source": [
        "run_lr_ohe(6)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6728871537494455, 0.6131553705177657, 0.6733605271415124)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0UzhSo9AlhD",
        "outputId": "1b0f667a-f9b2-4fcd-e4c9-56418bcc0840"
      },
      "source": [
        "run_lr_ohe(6)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6728871537494455, 0.6131553705177657, 0.6733605271415124)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c6AIRhfsgYM"
      },
      "source": [
        "#Function for XGBoost Classification\n",
        "def run_xgb_feat(fold):\n",
        "  #Apply Label encoder to the categorical features\n",
        "  for feature in train_features:\n",
        "    if feature in categorical_features:\n",
        "      #Initialize the Label Encoder\n",
        "      lbl = preprocessing.LabelEncoder()\n",
        "      #Fit the label encoder on each of the features\n",
        "      lbl.fit(modeling_dataset[feature])\n",
        "      #Transform \n",
        "      modeling_dataset.loc[:,feature] = lbl.transform(modeling_dataset[feature])\n",
        "  \n",
        "  #Get training and validation data using the fold\n",
        "  modeling_datasets_train = modeling_dataset[modeling_dataset.kfold != fold].reset_index(drop=True)\n",
        "  modeling_datasets_valid = modeling_dataset[modeling_dataset.kfold == fold].reset_index(drop=True)\n",
        "  \n",
        "  #Get the data for modeling - Selected features\n",
        "  modeling_dataset_features_train = modeling_datasets_train[train_features_after_selection].values\n",
        "  modeling_dataset_features_valid = modeling_datasets_valid[train_features_after_selection].values\n",
        "\n",
        "  #Standardizing the data because this is a Linear model\n",
        "  sc = StandardScaler()\n",
        "\n",
        "  scaled_modeling_datasets_train = sc.fit_transform(modeling_dataset_features_train)\n",
        "  scaled_modeling_datasets_valid = sc.transform(modeling_dataset_features_valid)\n",
        "\n",
        "  #Initialize the Logistic Regression Model\n",
        "  xgb_model = xgb.XGBClassifier(n_jobs=-1)\n",
        "\n",
        "  #Fit model on training data\n",
        "  xgb_model.fit(scaled_modeling_datasets_train, modeling_datasets_train.HasDetections.values)\n",
        "\n",
        "  #Predict on the validation data using the probability for the AUC\n",
        "  valid_preds = xgb_model.predict_proba(scaled_modeling_datasets_valid)[:, 1]\n",
        "  \n",
        "  #For precision and Recall\n",
        "  valid_preds_pc = xgb_model.predict(scaled_modeling_datasets_valid)\n",
        "\n",
        "  #Get the ROC AUC score\n",
        "  auc = metrics.roc_auc_score(modeling_datasets_valid.HasDetections.values, valid_preds)\n",
        "\n",
        "  #Get the precision score\n",
        "  pre = metrics.precision_score(modeling_datasets_valid.HasDetections.values, valid_preds_pc, average='binary')\n",
        "\n",
        "  #Get the Recall score  \n",
        "  rc = metrics.recall_score(modeling_datasets_valid.HasDetections.values, valid_preds_pc, average='binary')\n",
        "\n",
        "  return auc, pre, rc"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ERQFMsAs6Zk",
        "outputId": "2eb9529c-10d4-4127-c4fb-142ee571e106"
      },
      "source": [
        "run_xgb_feat(6)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.665272497127657, 0.6015925261643377, 0.6840961047111032)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnG3q5f_bmSo"
      },
      "source": [
        "#Function for the Neural Network Classifier - OHE\n",
        "def run_nn_ohe(fold):\n",
        "  #Get training and validation data using folds\n",
        "  cleaned_fold_datasets_train = modeling_dataset[modeling_dataset.kfold != fold].reset_index(drop=True)\n",
        "  cleaned_fold_datasets_valid = modeling_dataset[modeling_dataset.kfold == fold].reset_index(drop=True)\n",
        "  \n",
        "  #Initialize OneHotEncoder from scikit-learn, and fit it on training and validation features\n",
        "  ohe = preprocessing.OneHotEncoder()\n",
        "  full_data = pd.concat(\n",
        "    [cleaned_fold_datasets_train[train_features_after_selection],cleaned_fold_datasets_valid[train_features_after_selection]],\n",
        "    axis = 0\n",
        "    )\n",
        "  ohe.fit(full_data[train_features_after_selection])\n",
        "  \n",
        "  #transform the training and validation data\n",
        "  x_train = ohe.transform(cleaned_fold_datasets_train[train_features_after_selection])\n",
        "  x_valid = ohe.transform(cleaned_fold_datasets_valid[train_features_after_selection])\n",
        "\n",
        "  #Initialize the Neural Network Model\n",
        "  nn_model = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
        "\n",
        "  #Fit model on training data (ohe)\n",
        "  nn_model.fit(x_train , cleaned_fold_datasets_train.HasDetections.values)\n",
        "\n",
        "  #Predict on the validation data using the probability of 1s for the AUC\n",
        "  valid_preds = nn_model.predict_proba(x_valid)[:, 1]\n",
        "\n",
        "  valid_preds_pc = nn_model.predict(x_valid)\n",
        "\n",
        "\n",
        "  #Get the ROC AUC score\n",
        "  auc = metrics.roc_auc_score(cleaned_fold_datasets_valid.HasDetections.values, valid_preds)\n",
        "\n",
        "  #Get the precision score\n",
        "  pre = metrics.precision_score(cleaned_fold_datasets_valid.HasDetections.values, valid_preds_pc, average='binary')\n",
        "\n",
        "  #Get the Recall score\n",
        "  rc = metrics.recall_score(cleaned_fold_datasets_valid.HasDetections.values, valid_preds_pc, average='binary')\n",
        "\n",
        "  return auc, pre, rc"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhsSD7_0bmVW",
        "outputId": "c0305574-677e-4817-e007-4905afb036e2"
      },
      "source": [
        "run_nn_ohe(7)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6726697316542962, 0.6195997524241799, 0.6634999889534499)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf9lTTrn-4in"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}